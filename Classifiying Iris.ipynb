{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNc9ZB/gcKD/JFzZnScD+mC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SebastianHGR/curso-PYER/blob/master/Classifiying%20Iris.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5_ZiU04LaTA5"
      },
      "source": [
        "This notebook was created based on the instructions seen on the first chapter of the book \"Introduction to Machine Learning with Python\" writen by Andreas C. MÃ¼ller and Sarah Guido.\n",
        "no copyright infringement is intended, this notebook is for academic purposes only and should not be publically avalible."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m9XaYvUqItEj"
      },
      "source": [
        "!pip install mglearn\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import mglearn\n",
        "import numpy as np\n",
        "import pandas\n",
        "\n",
        "from sklearn.datasets import load_iris\n",
        "iris_dataset = load_iris()\n",
        "\n",
        "print(\"keys if iris_dataset: \\n{}\".format(iris_dataset.keys()))\n",
        "print(iris_dataset['DESCR'][:193]+\"\\n...\")\n",
        "print(\"target names: \\n{}\".format(iris_dataset['target_names']))\n",
        "print(\"Feature names: \\n{}\".format(iris_dataset['feature_names']))\n",
        "print(\"type of data: {}\".format(type(iris_dataset['data'])))\n",
        "print(\"Shape of data: {}\".format(iris_dataset['data'].shape))\n",
        "\n",
        "print(\"First five columns of data:\\n{}\".format(iris_dataset['data'][:5]))\n",
        "print(\"Type of target: {}\".format(type(iris_dataset['target'])))\n",
        "print(\"Shape of target: {}\".format(iris_dataset['target'].shape))\n",
        "print(\"Target:\\n{}\".format(iris_dataset['target']))\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(iris_dataset['data'], iris_dataset['target'], random_state=0)\n",
        "\n",
        "print(\"x_train shape: {}\".format(x_train.shape))\n",
        "print(\"y_train sahpe: {}\".format(y_train.shape))\n",
        "print(\"x_test shape: {}\".format(x_test.shape))\n",
        "print(\"y_test sahpe: {}\".format(y_test.shape))\n",
        "\n",
        "#label the columns using the strings in iris_dataset.feature_names\n",
        "iris_dataframe = pd.DataFrame(_train, columns=iris_dataset.feature_names)\n",
        "#create a scatter matrix from the dataframe, color by y_train\n",
        "grr = pd.plotting.scatter_matrix(iris_dataframe, c=y_train, figsize=(15, 15), marker='o',\n",
        "hist_kwds={'bins': 20}, s=60, alpha=.8, cmap=mglearn.cm3)\n",
        "\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "knn = KNeighborsClassifier(n_neighbors=1)\n",
        "knn.fit(x_train, y_train)\n",
        "x_new = np.array([[2, 2.9, 1, 0.2]])\n",
        "\n",
        "print(\"X_new.shape: {}\".format(x_new.shape))\n",
        "prediction = knn.predict(x_new)\n",
        "print(\"Prediction: {}\".format(prediction))\n",
        "print(\"Prediction target name: {}\".format(iris_dataset['target_names'][prediction]))\n",
        "y_pred = knn.predict(x_test)\n",
        "print(\"Test set predictions:\\n {}\".format(y_pred))\n",
        "print(\"Test set score: {:.2f}\".format(np.mean(y_pred == y_test)))\n",
        "print(\"Test set score: {:.2f}\".format(knn.score(x_test, y_test)))\n",
        "x_train, x_test, y_train, y_test = train_test_split(iris_dataset['data'], iris_dataset['target'], random_state=0)\n",
        "\n",
        "knn = KNeighborsClassifier(n_neighbors=1)\n",
        "knn.fit(x_train, y_train)\n",
        "\n",
        "print(\"Test set score: {:.2f}\".format(knn.score(x_test, y_test)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "66EhCxzLaJnt"
      },
      "source": [
        "The Actual Explanation\n",
        "The first set of Print commands until \"shape of data\" are the used for data entry and tagging of such thing like names, a brief description, its features, type and shape.\n",
        "The next set of prints arrenge said data\n",
        "The next set of prints arrange the data into a matrix. The species samples are stored in a NumPy array which is a one-dimensional array with space for just one input per sample."
      ]
    }
  ]
}